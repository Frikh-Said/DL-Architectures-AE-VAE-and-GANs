# DL-Architectures-AE-VAE-and-GANs

This lab is designed to enhance our understanding and practical skills in creating and training deep neural networks using PyTorch, focusing on Auto-encoders (AE), Variational Auto-encoders (VAE), and Generative Adversarial Networks (GANs).

## Part 1: AE and VAE
1. Develop and train an auto-encoder architecture on the MNIST dataset.
2. Develop and train a variational auto-encoder architecture on the MNIST dataset.
3. Evaluate and analyze both models (e.g., Loss, KL divergence).
4. Visualize the latent spaces of the AE and VAE models.

- MNIST Dataset for AE and VAE: [MNIST Dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)


## Part 2: GANs
1. Set up and train GAN architectures using the Abstract Art Gallery dataset.
2. Analyze the performance of both the Generator and Discriminator.
3. Generate new data and assess its quality compared to original data.

- Abstract Art Gallery for GANs: [Abstract Art Gallery Dataset](https://www.kaggle.com/datasets/bryanb/abstract-art-gallery)

